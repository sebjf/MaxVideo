package maxvideo;

import types.uRGB;

import com.maxeler.maxcompiler.v2.kernelcompiler.Kernel;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.Reductions;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Count.Counter;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.IO.DelimiterMode;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.IO.NonBlockingInput;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.IO.NonBlockingMode;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.KernelObject;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.KernelType;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEStruct;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEStructType;

import displaystandards.DisplayStandard;

/* This kernel is designed to collate the video data, and synchronise it with the control signals and the pixel clock.
 * When building for hardware, connect the displayDataOut output of this kernel to the video transmitter:
 *
 *  getVideoStream("displayDataOut", clock) <== maxVideoDataKernelBlock.getOutput("displayDataOut"); //this returns a stream to the display driver hardware
 *
 *  This kernel must be clocked at the same rate as the pixel clock, defined by the display standard. Create and set this like so:
 *
 *  ManagerClock pixelClock = generateStreamClock("pixelClock", kernel.Display.getDisplayClock());
 *  maxVideoDataKernelBlock.setClock(pixelClock);
 *
 *  */

public class MaxVideoSignalKernel extends Kernel {

	private <T extends KernelObject<T>> T makeInstrumentedNonBlockingInput(String name, KernelType<T> type, DFEVar enable)
	{
		NonBlockingInput<T> input =
			io.nonBlockingInput(name, type, constant.var(true), 1, DelimiterMode.FRAME_LENGTH, 0, NonBlockingMode.NO_TRICKLING);
		T data = Reductions.streamHold(input.data, input.valid);

		DFEVar stall = enable & (~input.valid);

		Counter sequentialStallCounter = control.count.makeCounter(control.count.makeParams(32).withEnable(stall).withReset(input.valid));
		DFEVar sequentialStallCount = sequentialStallCounter.getCount();

		io.scalarOutput(name + "_SequentialStalls", dfeUInt(32)).connect(Reductions.streamMax(sequentialStallCount));

		return data;
	}

	final public static String m_name = "MaxImageGenKernel";

	/* This is the counterpart of an identical type defined in VideoIOFactory.maxj */

	public static final DFEStructType VideoWordDataType =
		new DFEStructType(
				DFEStructType.sft("R", dfeUInt(8)),
				DFEStructType.sft("G", dfeUInt(8)),
				DFEStructType.sft("B", dfeUInt(8)),
				DFEStructType.sft("DE", dfeBool()),
				DFEStructType.sft("HSync", dfeBool()),
				DFEStructType.sft("VSync", dfeBool()),
				DFEStructType.sft("StartOfFrame", dfeBool()),
				DFEStructType.sft("EndOfFrame", dfeBool()),
				DFEStructType.sft("phaseCompensationFifoWrEn", dfeBool()),
				DFEStructType.sft("phaseCompensationFifoRdEn",dfeBool()),
				DFEStructType.sft("HalfClockEnable", dfeBool()),
				DFEStructType.sft("R2", dfeUInt(8)),
				DFEStructType.sft("G2", dfeUInt(8)),
				DFEStructType.sft("B2", dfeUInt(8)),
				DFEStructType.sft("Metadata", dfeRawBits(8)));

	public MaxVideoSignalKernel(KernelParameters parameters, DisplayStandard displayStandard) {
		super(parameters);

		flush.disabled();

		/* Get the display counters */

		VideoCounter counters = new VideoCounter(this, VideoCounter.Scope.Full);
		DFEVar x = counters.x.cast(dfeInt(32));
		DFEVar y = counters.y.cast(dfeInt(32));

		/* Create the output struct to map to the transmitter input */

		DFEStruct videoWord = VideoWordDataType.newInstance(this);

		/* Generate the control signals */

		DFEVar h_sync_polarity = io.scalarInput("HSyncPolarity", dfeBool());
		DFEVar v_sync_polarity = io.scalarInput("VSyncPolarity", dfeBool());

		//We assume we start on sync pulses, like so: http://docs.toradex.com/100270-colibri-display-convention-gn-454x384.gif

		videoWord["HSync"] 	<== (x < displayStandard.H_Sync).ternaryIf(h_sync_polarity, ~h_sync_polarity);
		videoWord["VSync"] 	<== (y < displayStandard.V_Sync).ternaryIf(v_sync_polarity, ~v_sync_polarity);

		DFEVar de			= (x >= displayStandard.H_Active_Start).and(x < displayStandard.H_Blank_Start).and(y >= displayStandard.V_Active_Start).and(y < displayStandard.V_Blank_Start);
		videoWord["DE"]		<== de;

		videoWord["StartOfFrame"] <== x.eq(0).and(y.eq(0));
		videoWord["EndOfFrame"]   <== x.eq(displayStandard.TotalWidth - 1).and(y.eq(displayStandard.TotalHeight - 1));

		/* Get the colour inputs */

		DFEVar rgb1 = io.input("rgb", dfeUInt(24), de.cast(dfeBool()));

		/* Extract and format the colour data */

		uRGB colourData = new uRGB(rgb1);
		videoWord["R"] <== colourData.m_R.cast(dfeUInt(8));
		videoWord["G"] <== colourData.m_G.cast(dfeUInt(8));
		videoWord["B"] <== colourData.m_B.cast(dfeUInt(8));


		/* Generate the phase compensation fifo control signals */

		videoWord["phaseCompensationFifoWrEn"] <== constant.var(dfeBool(), 0);
		videoWord["phaseCompensationFifoRdEn"] <== constant.var(dfeBool(), 0);

		/* Debug and test pattern signalling */

		if(displayStandard.enableHalfPatternInput){
			videoWord["HalfClockEnable"] <== io.input("HalfClockEnable", dfeBool());
		}else{
			videoWord["HalfClockEnable"] <== constant.var(dfeBool(),0);
		}

		/* Tie down the remaining unused inputs */

		videoWord["R2"] <== constant.var(dfeUInt(8),0);
		videoWord["G2"] <== constant.var(dfeUInt(8),0);
		videoWord["B2"] <== constant.var(dfeUInt(8),0);

		videoWord["Metadata"] <== constant.var(dfeRawBits(8),0);

		/* Transmit the formatted word to the video transmitter */

		io.output("displayDataOut", dfeRawBits(64)) <== videoWord.pack();

	}


}
